{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4fab6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic dependencies\n",
    "\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from numpy import savetxt\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "###########\n",
    "\n",
    "# torch dependencies\n",
    "import torch\n",
    "\n",
    "tkwargs = {\"dtype\": torch.double, # set as double to minimize zero error for cholesky decomposition error\n",
    "           \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")} # set tensors to GPU, if multiple GPUs please set cuda:x properly\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "###########\n",
    "\n",
    "# plotting dependencies\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# sk dependencies\n",
    "import sklearn\n",
    "\n",
    "# data related\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "\n",
    "# surrogate model specific\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "\n",
    "# qNEHVI specific\n",
    "from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qNoisyExpectedHypervolumeImprovement\n",
    "\n",
    "# utilities\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# pymoo dependencies\n",
    "import pymoo\n",
    "\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "from pymoo.core.problem import ElementwiseProblem, Problem\n",
    "\n",
    "from pymoo.algorithms.moo.unsga3 import UNSGA3\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.core.termination import NoTermination\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b6ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_train_model (train_x_gp, train_obj):\n",
    "    \n",
    "    # define and train surrogate models for objective and constraint\n",
    "    models = []\n",
    "\n",
    "    # models for objective\n",
    "\n",
    "    for i in range(train_obj.shape[-1]):\n",
    "        models.append(SingleTaskGP(train_x_gp, train_obj[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "\n",
    "    model = ModelListGP(*models)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    fit_gpytorch_model(mll) \n",
    "\n",
    "    acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "        model=model,\n",
    "        ref_point=ref_point, # for computing HV, must flip for BoTorch\n",
    "        X_baseline=train_x_gp, # feed total list of train_x for this current iteration\n",
    "        sampler=SobolQMCNormalSampler(num_samples=128),  # determines how candidates are randomly proposed before selection\n",
    "        objective=IdentityMCMultiOutputObjective(outcomes=np.arange(n_obj).tolist()), # optimize first n_obj col \n",
    "        #constraints=create_idxrs(), # constraint on last n_constr col\n",
    "        prune_baseline=True, cache_pending=True)  # options for improving qNEHVI, keep these on\n",
    "    \n",
    "    return model, acq_func\n",
    "\n",
    "def func_model_accuracy(train_x_gp, train_obj, model):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # just the training set\n",
    "        posterior = model.posterior(train_x_gp)\n",
    "        y_pred = posterior.mean\n",
    "        lower, upper = posterior.mvn.confidence_region()\n",
    "        error = upper-lower\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = train_obj.shape[1], figsize = (train_obj.shape[1]*4,4))\n",
    "\n",
    "    # plot objective predictions\n",
    "    for i in np.arange(train_obj.shape[1]).tolist():\n",
    "\n",
    "        score1 = r2_score(train_obj[:,i].cpu().numpy(), y_pred[:,i].cpu().numpy())\n",
    "        score2 = mean_squared_error(train_obj[:,i].cpu().numpy(), y_pred[:,i].cpu().numpy())\n",
    "\n",
    "        ax[i].axline((1, 1), slope=1)\n",
    "\n",
    "        ax[i].errorbar(x=train_obj[:,i].cpu().numpy(), y=y_pred[:,i].cpu().numpy(), yerr=error[:,i].cpu().numpy(),\n",
    "                       ls='', marker='D', mec='w', mew=0.2, mfc='b', c='b', alpha=0.35,\n",
    "                        label='Trained Points'\n",
    "                       )\n",
    "\n",
    "        ax[i].set_title(f\"f{i}\", fontsize=18)\n",
    "        ax[i].set_xlabel('True Value', fontsize=14)\n",
    "\n",
    "        textstr = 'R2-score:'+str('%.7f'%score1)+'\\n'+'MSE-score:'+str('%.4E'%score2)\n",
    "        props = dict(boxstyle='square', facecolor='white', alpha=0.5)\n",
    "        # place a text box in upper left in axes coords\n",
    "        ax[i].text(0.05, 0.95, textstr, transform=ax[i].transAxes, fontsize=11,\n",
    "                verticalalignment='top', bbox=props)\n",
    "\n",
    "    ax[0].set_ylabel('Predicted Value', fontsize=14)\n",
    "\n",
    "def func_repair (candidates): \n",
    "    \n",
    "    # repair inputs to feasibility\n",
    "    for i in range(candidates.shape[0]):\n",
    "        if 0.3 - candidates[i,1]/candidates[i,4] > 0:\n",
    "            candidates[i,4] = min(candidates[i,1]/0.3, candidates[i,4])\n",
    "\n",
    "    for i in range(candidates.shape[0]):\n",
    "        if 2 - (candidates[i,1]/candidates[i,4]) - (candidates[i,3]/candidates[i,1]) > 0:\n",
    "            candidates[i,3] = max((2-candidates[i,1]/candidates[i,4])*candidates[i,1], candidates[i,3])\n",
    "    return candidates\n",
    "\n",
    "def func_unsga3 (train_x_gp, train_obj):\n",
    "    \n",
    "    # we pick out the best points so far to form parents\n",
    "    pareto_mask = is_non_dominated(train_obj)\n",
    "    pareto_y = -train_obj[pareto_mask]\n",
    "    pareto_x = train_x_gp[pareto_mask]\n",
    "\n",
    "    algorithm = UNSGA3(pop_size=256,\n",
    "                       ref_dirs=get_reference_directions(\"energy\", n_obj, BATCH_SIZE, seed=random_state),\n",
    "                       sampling=pareto_x.cpu().numpy(),\n",
    "                      )\n",
    "\n",
    "    pymooproblem = Problem(n_var=n_var, n_obj=n_obj, xl=np.zeros(n_var), xu=np.ones(n_var))\n",
    "    algorithm.setup(pymooproblem, termination=NoTermination())\n",
    "\n",
    "    # set the 1st population to the current evaluated population\n",
    "    pop = algorithm.ask()\n",
    "    pop.set(\"F\", pareto_y.cpu().numpy())\n",
    "    algorithm.tell(infills=pop)\n",
    "\n",
    "    # propose children based on tournament selection -> crossover/mutation\n",
    "    newpop = algorithm.ask()\n",
    "    nsga3_x = torch.tensor(newpop.get(\"X\"), **tkwargs)\n",
    "    nsga3_x = unnormalize(nsga3_x, bounds=problem_bounds)\n",
    "    \n",
    "    return nsga3_x\n",
    "\n",
    "def func_optimization (candidates, model):\n",
    "\n",
    "    acq_list, pred_list, uncertainty_list = [], [], []\n",
    "    for i in range(0, candidates.shape[0]):\n",
    "        with torch.no_grad():\n",
    "            acq_value = acq_func(candidates[i].unsqueeze(dim=0))\n",
    "            acq_list.append(acq_value.item())\n",
    "\n",
    "            posterior = model.posterior(candidates[i].unsqueeze(0))\n",
    "            pred_list.append(posterior.mean[0].cpu().numpy())\n",
    "            lower, upper = posterior.mvn.confidence_region()\n",
    "            uncertainty_list.append(upper[0].cpu().numpy() - lower[0].cpu().numpy())\n",
    "\n",
    "    sorted_x = candidates.cpu().numpy()[np.argsort((acq_list))]\n",
    "    new_x = torch.tensor(sorted_x[-BATCH_SIZE:], **tkwargs)  # take best BATCH_SIZE samples from sorted pool\n",
    "\n",
    "    return new_x, acq_list, pred_list, uncertainty_list\n",
    "\n",
    "def func_plot_monitoring (acq_list, pred_list, uncertainty_list):\n",
    "    \n",
    "    acq_plot = np.array(acq_list)\n",
    "    pred_plot = np.array(pred_list)\n",
    "    uncertainty_plot = np.array(uncertainty_list)\n",
    "\n",
    "    views = [(1, (0, -45, 0)),\n",
    "             (2, (0, 45, 0)),\n",
    "             (3, (0, 135, 0)),]\n",
    "    layout = [[1, 2, 3]]  \n",
    "\n",
    "    norm = plt.Normalize(acq_plot.min(), acq_plot.max())\n",
    "    fig, ax = plt.subplot_mosaic(layout, subplot_kw={'projection': '3d'},\n",
    "                                  figsize=(21, 7))\n",
    "\n",
    "    for plane, angles in views:\n",
    "\n",
    "        ax[plane].scatter3D(pred_plot[:,0], pred_plot[:,1], pred_plot[:,2],\n",
    "                            c=acq_plot, s=20, norm=norm, cmap='viridis', alpha=0.15)\n",
    "\n",
    "        high = pred_plot[np.argsort((acq_plot))][-BATCH_SIZE:]\n",
    "        ax[plane].scatter3D(high[:,0], high[:,1], high[:,2],\n",
    "                            c='y', s=100, marker='*', alpha=0.9)\n",
    "\n",
    "        ax[plane].set_xlabel('f1', fontsize=11)\n",
    "        ax[plane].set_ylabel('f2', fontsize=11)\n",
    "        ax[plane].set_zlabel('f3', fontsize=11)\n",
    "\n",
    "        ax[plane].set_xlim(initial_x_pandas['y1'].min(), initial_x_pandas['y1'].max())\n",
    "        ax[plane].set_ylim(initial_x_pandas['y2'].min(), initial_x_pandas['y2'].max())\n",
    "        ax[plane].set_zlim(initial_x_pandas['y3'].min(), initial_x_pandas['y3'].max())\n",
    "\n",
    "        ax[plane].view_init(azim=angles[1])\n",
    "\n",
    "    ax[2].set_title(f\"Predicted Candidates wrt to AcqValue, proposed batch in yellow\", fontsize=18)\n",
    "\n",
    "    norm = plt.Normalize(uncertainty_plot.sum(axis=1).min(), uncertainty_plot.sum(axis=1).max())\n",
    "    fig, ax = plt.subplot_mosaic(layout, subplot_kw={'projection': '3d'},\n",
    "                                  figsize=(21, 7))\n",
    "\n",
    "    for plane, angles in views:\n",
    "\n",
    "        ax[plane].scatter3D(pred_plot[:,0], pred_plot[:,1], pred_plot[:,2],\n",
    "                            c=uncertainty_plot.sum(axis=1), s=20, norm=norm, cmap='Blues', alpha=0.15)\n",
    "\n",
    "        high = pred_plot[np.argsort((acq_plot))][-BATCH_SIZE:]\n",
    "        ax[plane].scatter3D(high[:,0], high[:,1], high[:,2],\n",
    "                            c='y', s=100, marker='*', alpha=0.9)\n",
    "\n",
    "        ax[plane].set_xlabel('f1', fontsize=11)\n",
    "        ax[plane].set_ylabel('f2', fontsize=11)\n",
    "        ax[plane].set_zlabel('f3', fontsize=11)\n",
    "\n",
    "        ax[plane].set_xlim(initial_x_pandas['y1'].min(), initial_x_pandas['y1'].max())\n",
    "        ax[plane].set_ylim(initial_x_pandas['y2'].min(), initial_x_pandas['y2'].max())\n",
    "        ax[plane].set_zlim(initial_x_pandas['y3'].min(), initial_x_pandas['y3'].max())\n",
    "\n",
    "        ax[plane].view_init(azim=angles[1])\n",
    "\n",
    "    ax[2].set_title(f\"Predicted Candidates wrt to Uncertainty, proposed batch in yellow\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193f8920",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## settings to change every day\n",
    "\n",
    "total_exp = 16 # total sets of experiments to run today\n",
    "\n",
    "algo = 'pure' # start from pure\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "########## settings to keep, used for some parts of the code\n",
    "\n",
    "exp_counter = 15 # current number of experiments done, start with 0 for initialization\n",
    "\n",
    "n_var = 5\n",
    "n_obj = 3\n",
    "\n",
    "random_state = 1\n",
    "torch.manual_seed(random_state) # gives a consistent seed based on the trial number\n",
    "\n",
    "ref_point = torch.tensor([0, 0, 0], **tkwargs)\n",
    "hv=Hypervolume(ref_point=ref_point)\n",
    "\n",
    "problem_bounds = torch.zeros(2, n_var, **tkwargs)\n",
    "problem_bounds[0] = 0.6\n",
    "problem_bounds[1] = 24.0\n",
    "\n",
    "standard_bounds = torch.zeros(2, n_var, **tkwargs)\n",
    "standard_bounds[1] = 1\n",
    "\n",
    "initial_sample_size = 12 # no of initialized LHS samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while exp_counter < total_exp+1:\n",
    "    t0 = time.time()\n",
    "     \n",
    "    ##########\n",
    "    # load data from matlab/labview into jupyter       \n",
    "    if algo == 'pure':\n",
    "        input_file = \"Data Analysis/Algo1/Results_Algo1_Run\" + str(exp_counter) + \".csv\"\n",
    "        if Path(input_file).is_file() == False:\n",
    "            print(\"No input file detected, sleeping for 30 sec\")\n",
    "            time.sleep(30)\n",
    "            continue;\n",
    "            \n",
    "        initial_x_pandas = pd.read_csv(f\"{input_file}\", delimiter=',') \n",
    "        initial_x_torch = torch.tensor(initial_x_pandas.iloc[:,1:].values, **tkwargs) \n",
    "        \n",
    "    else:\n",
    "        input_file = \"Data Analysis/Algo2/Results_Algo2_Run\" + str(exp_counter) + \".csv\"\n",
    "        if Path(input_file).is_file() == False:\n",
    "            print(\"No input file detected, sleeping for 30 sec\")\n",
    "            time.sleep(30)\n",
    "            continue;\n",
    "            \n",
    "        initial_x_pandas = pd.read_csv(f\"{input_file}\", delimiter=',') \n",
    "        initial_x_torch = torch.tensor(initial_x_pandas.iloc[:,1:].values, **tkwargs) \n",
    "        \n",
    "    print(\"File successfully found! Proceeding with optimization.\")\n",
    "\n",
    "    ####################\n",
    "    # initial training data\n",
    "    train_x = initial_x_torch[:,:n_var]\n",
    "    train_x_gp = normalize(train_x, problem_bounds)\n",
    "    train_obj = initial_x_torch[:,n_var:n_var+n_obj]\n",
    "\n",
    "    # surrogate model\n",
    "    model, acq_func = func_train_model(train_x_gp, train_obj)\n",
    "    model.eval()\n",
    "    func_model_accuracy(train_x_gp, train_obj, model)\n",
    "\n",
    "    ####################    \n",
    "    # optimization\n",
    "\n",
    "    if algo == 'pure':\n",
    "        \n",
    "        print(\"Performing pure BO.\")\n",
    "\n",
    "        # taking 256 x 2 QMC candidates\n",
    "        sobol_x1 = draw_sobol_samples(bounds=problem_bounds,n=256, q=1).squeeze(1)\n",
    "        sobol_x2 = draw_sobol_samples(bounds=problem_bounds,n=256, q=1).squeeze(1)\n",
    "        candidates = torch.cat([sobol_x1, sobol_x2])\n",
    "        candidates = func_repair(candidates)\n",
    "        candidates = normalize(candidates, problem_bounds)\n",
    "        \n",
    "        new_x, acq_list, pred_list, uncertainty_list = func_optimization(candidates, model)\n",
    "\n",
    "        func_plot_monitoring(acq_list, pred_list, uncertainty_list)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(\"Performing hybrid BO+EA.\")\n",
    "        \n",
    "        # taking 256 x 1 QMC candidates and 256 x 1 evolution candidates\n",
    "        sobol_x = draw_sobol_samples(bounds=problem_bounds,n=256, q=1).squeeze(1)\n",
    "        nsga3_x = func_unsga3(train_x_gp, train_obj)\n",
    "        candidates = torch.cat([sobol_x, nsga3_x])\n",
    "        candidates = func_repair(candidates)\n",
    "        candidates = normalize(candidates, problem_bounds)\n",
    "        \n",
    "        new_x, acq_list, pred_list, uncertainty_list = func_optimization(candidates, model)\n",
    "\n",
    "        func_plot_monitoring(acq_list, pred_list, uncertainty_list)\n",
    "        \n",
    "        candidate_check = torch.cat([torch.zeros(sobol_x.shape[0]), torch.ones(nsga3_x.shape[0])])[np.argsort((acq_list))][-BATCH_SIZE:].cpu().numpy()\n",
    "\n",
    "    ####################\n",
    "    # end of optimization loop\n",
    "\n",
    "    # unormalize our training inputs back to original problem bounds\n",
    "    new_x =  unnormalize(new_x, bounds=problem_bounds)\n",
    "    \n",
    "    #################### \n",
    "    t1 = time.time()\n",
    "    \n",
    "    # convert back to matlab/labview format for downloading\n",
    "    new_x_pandas = pd.DataFrame(new_x.cpu().numpy(), columns=['Qtsc', 'Qag', 'Qpva', 'Qseed', 'Qaa'])\n",
    "    new_x_pandas['Cond'] = new_x_pandas.index + BATCH_SIZE*exp_counter + initial_sample_size + 1\n",
    "    new_x_pandas['Repair'] = repair_array\n",
    "    new_x_pandas['Violation1'] = constraint_array1\n",
    "    new_x_pandas['Violation2'] = constraint_array2\n",
    "    new_x_pandas['Time'] =  t1-t0\n",
    "    new_x_pandas['Candidate Check'] = candidate_check\n",
    "    new_x_pandas = new_x_pandas[['Cond', 'Qtsc', 'Qag', 'Qpva', 'Qseed', 'Qaa', 'Repair', 'Violation1', 'Violation2', 'Time', 'Candidate Check']] \n",
    "        \n",
    "        \n",
    "    # Save new flowrate values in csv files before shuffling\n",
    "    if algo == 'pure':\n",
    "        output_file = \"Flowrates/Flowrates_Algo1_BS_Run\" + str(exp_counter+1)\n",
    "        new_x_pandas.to_csv(f'{output_file}.csv', index=False)\n",
    "        \n",
    "    else:\n",
    "        output_file = \"Flowrates/Flowrates_Algo2_BS_Run\" + str(exp_counter+1)\n",
    "        new_x_pandas.to_csv(f'{output_file}.csv', index=False)\n",
    "        \n",
    "         # Shuffle flowrate\n",
    "        input_file = \"Flowrates/Flowrates_Algo1_BS_Run\" + str(exp_counter+1) + \".csv\"            \n",
    "        dataAlgo1_pandas = pd.read_csv(f\"{input_file}\", delimiter=',') \n",
    "        dataAlgo1_torch = torch.tensor(dataAlgo1_pandas.iloc[:,:].values, **tkwargs)\n",
    "\n",
    "        input_file = \"Flowrates/Flowrates_Algo2_BS_Run\" + str(exp_counter+1) + \".csv\"            \n",
    "        dataAlgo2_pandas = pd.read_csv(f\"{input_file}\", delimiter=',') \n",
    "        dataAlgo2_torch = torch.tensor(dataAlgo2_pandas.iloc[:,:].values, **tkwargs)\n",
    "   \n",
    "        iOrder = [0,4,1,5,2,6,3,7]\n",
    "        iSave = 4\n",
    "        pSave = [0,1,2,3]\n",
    "        qSave = [0,1,2,3]\n",
    "            \n",
    "        for p in multiset_permutations([0,1,2,3]):\n",
    "            for q in multiset_permutations([0,1,2,3]):\n",
    "                dataAlgo_torch = torch.vstack([dataAlgo1_torch[p,1:6], dataAlgo2_torch[q,1:6]])\n",
    "                dataAlgoOrder_torch = dataAlgo_torch[iOrder]\n",
    "\n",
    "                Test = dataAlgoOrder_torch\n",
    "                Test[Test <= 4] = 1\n",
    "                Test[Test > 4] = 0\n",
    "\n",
    "                # Cumulative sum\n",
    "                cumsumsave = torch.zeros(2*BATCH_SIZE-1, 1, **tkwargs)\n",
    "                for i in range(2*BATCH_SIZE-1):\n",
    "                    cumsum = torch.sum(Test[i:i+2],0)\n",
    "                    cumsumsave[i] = max(cumsum)\n",
    "\n",
    "                if(max(cumsumsave) < 2) & (iSave > 1):\n",
    "                    pSave = p\n",
    "                    qSave = q\n",
    "                    iSave = 1\n",
    "                    print(Test)\n",
    "                    print(iSave)\n",
    "                    print(pSave)\n",
    "                    print(qSave)\n",
    "                else:\n",
    "                    # Cumulative sum\n",
    "                    cumsumsave = torch.zeros(2*BATCH_SIZE-2, 1, **tkwargs)\n",
    "                    for i in range(2*BATCH_SIZE-2):\n",
    "                        cumsum = torch.sum(Test[i:i+3],0)\n",
    "                        cumsumsave[i] = max(cumsum)\n",
    "                    \n",
    "                    if(max(cumsumsave) < 3) & (iSave > 2):\n",
    "                        pSave = p\n",
    "                        qSave = q\n",
    "                        iSave = 2\n",
    "                        print(Test)\n",
    "                        print(iSave)\n",
    "                        print(pSave)\n",
    "                        print(qSave)\n",
    "                    else:\n",
    "                        # Cumulative sum\n",
    "                        cumsumsave = torch.zeros(2*BATCH_SIZE-3, 1, **tkwargs)\n",
    "                        for i in range(2*BATCH_SIZE-3):\n",
    "                            cumsum = torch.sum(Test[i:i+4],0)\n",
    "                            cumsumsave[i] = max(cumsum)\n",
    "\n",
    "                        if(max(cumsumsave) < 4) & (iSave > 3):\n",
    "                            pSave = p\n",
    "                            qSave = q\n",
    "                            iSave = 3\n",
    "                            print(Test)\n",
    "                            print(iSave)\n",
    "                            print(pSave)\n",
    "                            print(qSave)\n",
    "                \n",
    "        print(pSave)\n",
    "        print(qSave)\n",
    "        \n",
    "        dataAlgo_torch = torch.vstack([dataAlgo1_torch[pSave], dataAlgo2_torch[qSave]])\n",
    "        dataAlgoOrder_torch = dataAlgo_torch[iOrder]\n",
    "        new_dataAlgo1_pandas = pd.DataFrame(dataAlgo1_torch[pSave,:].cpu().numpy(), columns=['Cond', 'Qtsc', 'Qag', 'Qpva', 'Qseed', 'Qaa', 'Repair', 'Violation1', 'Violation2', 'Time'])\n",
    "        new_dataAlgo2_pandas = pd.DataFrame(dataAlgo2_torch[qSave,:].cpu().numpy(), columns=['Cond', 'Qtsc', 'Qag', 'Qpva', 'Qseed', 'Qaa', 'Repair', 'Violation1', 'Violation2', 'Time'])\n",
    "        \n",
    "        new_dataAlgo1_pandas['Cond'] = new_dataAlgo1_pandas.index + BATCH_SIZE*exp_counter + initial_sample_size + 1\n",
    "        new_dataAlgo2_pandas['Cond'] = new_dataAlgo2_pandas.index + BATCH_SIZE*exp_counter + initial_sample_size + 1\n",
    "\n",
    "        # Save new flowrate values in csv files after shuffling\n",
    "        output_file = \"Flowrates/Flowrates_Algo1_Run\" + str(exp_counter+1)\n",
    "        new_dataAlgo1_pandas.to_csv(f'{output_file}.csv', index=False)\n",
    "\n",
    "        output_file = \"Flowrates/Flowrates_Algo2_Run\" + str(exp_counter+1)\n",
    "        new_dataAlgo2_pandas.to_csv(f'{output_file}.csv', index=False)\n",
    "\n",
    "    #################### \n",
    "    # end of experiment loop\n",
    "        \n",
    "    if algo == 'pure':\n",
    "        print(f\"Experiment number {exp_counter} for pure BO , time taken: {t1-t0:>4.2f}s.\\nTotal experiments run: {exp_counter}\")\n",
    "        algo = 'hybrid' # switch to next algo\n",
    "\n",
    "    else:\n",
    "        print(f\"Experiment number {exp_counter} for hybrid BO, time taken: {t1-t0:>4.2f}s.\\nTotal experiments run: {exp_counter}\")\n",
    "        algo = 'pure'  # switch to next algo\n",
    "        exp_counter+=1\n",
    "    \n",
    "    print(\"Sleeping for 5 seconds before next experiment.\")\n",
    "    time.sleep(5) # pause for x sec\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
