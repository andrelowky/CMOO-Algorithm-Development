{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4fab6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic dependencies\n",
    "\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from numpy import savetxt\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "###########\n",
    "\n",
    "# torch dependencies\n",
    "import torch\n",
    "\n",
    "tkwargs = {\"dtype\": torch.double, # set as double to minimize zero error for cholesky decomposition error\n",
    "           #\"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")} # set tensors to GPU, if multiple GPUs please set cuda:x properly\n",
    "           \"device\": torch.device(\"cpu\")}\n",
    "\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "###########\n",
    "\n",
    "# botorch dependencies\n",
    "import botorch\n",
    "\n",
    "# data related\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "\n",
    "# surrogate model specific\n",
    "from botorch.models.gp_regression import SingleTaskGP, FixedNoiseGP\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch import fit_gpytorch_model\n",
    "\n",
    "# qNEHVI specific\n",
    "from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qNoisyExpectedHypervolumeImprovement\n",
    "\n",
    "# utilities\n",
    "from botorch.optim.optimize import optimize_acqf, optimize_acqf_list\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "\n",
    "\n",
    "from gpytorch.constraints import GreaterThan\n",
    "from torch.optim import SGD\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "###########\n",
    "\n",
    "# pymoo dependencies\n",
    "import pymoo\n",
    "\n",
    "from pymoo.factory import get_problem\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.algorithms.moo.unsga3 import UNSGA3\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.core.termination import NoTermination\n",
    "\n",
    "from pymoo.core.problem import Problem\n",
    "\n",
    "###########\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import qmc\n",
    "from scipy.stats import gaussian_kde # for density plot\n",
    "\n",
    "###########\n",
    "\n",
    "# plotting dependencies\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# this is for the colorbar, you can change the cmap if you prefer other colour schemes\n",
    "from matplotlib.cm import ScalarMappable\n",
    "cm = plt.cm.get_cmap('viridis')\n",
    "\n",
    "# function to return the std dev across runs\n",
    "def ci(y, N_TRIALS):\n",
    "    return 1.96 * y.std(axis=0) / np.sqrt(N_TRIALS)\n",
    "\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0fddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_qnehvi(problem, ref_point, initial_x, # must haves\n",
    "                    N_BATCH, BATCH_SIZE, \n",
    "                    random_state=torch.randint(1000000, (1,)).item(), noise=0, verbose=False): # change noise here!\n",
    "    \n",
    "    print(\"Optimizing with Pure qNEHVI\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # some initializing \n",
    "    torch.manual_seed(random_state) # gives a consistent seed based on the trial number\n",
    "    hv=Hypervolume(ref_point=ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "    hvs = [] # create a blank array to append the scores at each batch/iteration for that run\n",
    "    \n",
    "    ##########\n",
    "    # generate initial training data for that run\n",
    "    train_x = initial_x\n",
    "    train_obj, train_con = problem.evaluate(train_x)\n",
    "\n",
    "    # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "    train_obj_noisy = train_obj + noise*torch.randn_like(train_obj)\n",
    "    train_con_noisy = train_con + noise*torch.randn_like(train_con)\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # normalize inputs to [0,1] first before feeding into model\n",
    "    standard_bounds = torch.zeros(2, problem.n_var, **tkwargs)\n",
    "    standard_bounds[1] = 1\n",
    "    train_x_gp = normalize(train_x, problem.bounds)\n",
    "    \n",
    "    # form the output train_y data by concentenating ground truth train_obj with its feasibility value on the rightmost\n",
    "    # this is necessary since the surrogate GpyTorch model needs to model BOTH obj and con for predicted candidates\n",
    "    train_y = torch.cat([train_obj_noisy, train_con_noisy], dim=-1) # model takes noisy observations\n",
    "\n",
    "    # define and train surrogate models for objective and constraint\n",
    "    models = []\n",
    "    for i in range(train_y.shape[-1]):\n",
    "        models.append(SingleTaskGP(train_x_gp, train_y[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "    model = ModelListGP(*models)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "        \n",
    "    ##########    \n",
    "    \n",
    "    def create_idxr(i):\n",
    "        def idxr(Z):\n",
    "            return Z[..., i]\n",
    "\n",
    "        return idxr\n",
    "\n",
    "    def create_idxrs():\n",
    "        return [create_idxr(i=i) for i in range(problem.n_obj, problem.n_obj+problem.n_constr)]\n",
    "    \n",
    "    # original location for an extra HV check wrt to initial samples\n",
    "    \n",
    "    ########## ########## ########## start of iteration loop\n",
    "\n",
    "\n",
    "    # training loop for N_BATCH iterations\n",
    "    for iteration in range(1, N_BATCH + 1):    \n",
    "\n",
    "        t3 = time.time()\n",
    "                \n",
    "        # fit the surrogate model\n",
    "        fit_gpytorch_model(mll)    \n",
    "                \n",
    "        ##########\n",
    "            \n",
    "        # define the acqusition function for EIC if feas_weighting is false\n",
    "        acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "            model=model,\n",
    "            ref_point=ref_point, # for computing HV, must flip for BoTorch\n",
    "            X_baseline=train_x_gp, # feed total list of train_x for this current iteration\n",
    "            sampler=SobolQMCNormalSampler(num_samples=128),  # determines how candidates are randomly proposed before selection\n",
    "            objective=IdentityMCMultiOutputObjective(outcomes=np.arange(problem.n_obj).tolist()), # optimize first n_obj col \n",
    "            constraints=create_idxrs(), # constraint on last n_constr col\n",
    "            prune_baseline=True, cache_pending=True)  # options for improving qNEHVI, keep these on\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # propose candidates given defined qNEHVI acq func given model and latest observed training data\n",
    "        new_x, _ = optimize_acqf(\n",
    "                        acq_function=acq_func,\n",
    "                        bounds=standard_bounds, # since train_x was normalized\n",
    "                        q=BATCH_SIZE, # no of candidates to propose in parallel\n",
    "                        num_restarts=2, # no of restarts of raw_samples\n",
    "                        raw_samples=256,  # pool of samples to choose the starting points from\n",
    "                        options={\"batch_limit\": 5, \"maxiter\": 200}, # default arguments, not too sure about this yet\n",
    "                        )\n",
    "\n",
    "        # unormalize our training inputs back to original problem bounds\n",
    "        new_x =  unnormalize(new_x.detach(), bounds=problem.bounds)\n",
    "        \n",
    "        # repair new_x\n",
    "        for i in range(new_x.shape[0]):\n",
    "            if 0.3 - new_x[i,1]/new_x[i,4] > 0:\n",
    "                new_x[i,4] = min(new_x[i,1]/0.3, new_x[i,4])\n",
    "\n",
    "        for i in range(new_x.shape[0]):\n",
    "            if 2 - (new_x[i,1]/new_x[i,4]) - (new_x[i,3]/new_x[i,1]) > 0:\n",
    "                new_x[i,3] = max((2-new_x[i,1]/new_x[i,4])*new_x[i,1], new_x[i,3])\n",
    "                \n",
    "        # feed new proposed observations into objective func to get its new ground truth\n",
    "        new_obj, new_con = problem.evaluate(new_x)\n",
    "\n",
    "        # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "        new_obj_noisy = new_obj + noise*torch.randn_like(new_obj)\n",
    "        new_con_noisy = new_con + noise*torch.randn_like(new_con)\n",
    "\n",
    "        # update training points by concatenating the new values into their respective tensors\n",
    "        train_x = torch.cat([train_x, new_x])\n",
    "        train_obj = torch.cat([train_obj, new_obj])\n",
    "        train_con = torch.cat([train_con, new_con])\n",
    "        train_obj_noisy = torch.cat([train_obj_noisy, new_obj_noisy])\n",
    "        train_con_noisy = torch.cat([train_con_noisy, new_con_noisy])\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        # computing HV of current candidate list\n",
    "        is_feas = (train_con <= 0).all(dim=-1) # check whether points fit ALL (.all) constraint criteria\n",
    "        feas_train_obj = train_obj[is_feas] # take only points that fit the 1st check\n",
    "        if feas_train_obj.shape[0] > 0:\n",
    "            pareto_mask = is_non_dominated(feas_train_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "            pareto_y = feas_train_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "            volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "        else:\n",
    "            volume = 0.0\n",
    "        \n",
    "        hvs.append(volume)\n",
    "        \n",
    "        ##########\n",
    "\n",
    "        # update the surrogate models for next iteration\n",
    "        train_x_gp = normalize(train_x, problem.bounds) # dont forget to renormalize!\n",
    "        train_y = torch.cat([train_obj_noisy, train_con_noisy], dim=-1) # model takes noisy observations\n",
    "\n",
    "        models = []\n",
    "        for i in range(train_y.shape[-1]):\n",
    "            models.append(SingleTaskGP(train_x_gp, train_y[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "        model = ModelListGP(*models)\n",
    "        mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "        \n",
    "        ##########\n",
    "        \n",
    "        t4 = time.time()\n",
    "        if verbose:\n",
    "            print(\n",
    "                    f\"Batch {iteration:>2} of {N_BATCH}: Hypervolume = \"\n",
    "                    f\"{hvs[-1]:>4.2f}, \"\n",
    "                    f\"time = {t4-t3:>4.2f}s.\\n\"\n",
    "                    , end=\"\")\n",
    "            \n",
    "        del new_x, new_obj, new_con, new_obj_noisy, new_con_noisy, train_y\n",
    "        torch.cuda.empty_cache() # clear some memory here between each run/trial     \n",
    "        \n",
    "        ########## ########## ########## end of iteration loop\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f\"Time taken in total: {t1-t0:>4.2f}s.\")       \n",
    "    \n",
    "    # returns the HV score across iterations, total training set as an array\n",
    "    return hvs, torch.hstack([train_x, train_obj, train_con]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20cab9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hybrid_nsga(problem, ref_point, initial_x, # must haves\n",
    "                         N_BATCH, BATCH_SIZE, \n",
    "                         random_state=torch.randint(1000000, (1,)).item(), noise=0, verbose=False): # change noise here!\n",
    "    \n",
    "    print(\"Optimizing with Hybrid qNEHVI + U-NSGA-III\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    torch.manual_seed(random_state) # gives a consistent seed based on the trial number\n",
    "    hv=Hypervolume(ref_point=ref_point) # sets the hv based on problem, flip since BoTorch takes maximisation\n",
    "    hvs = [] # create a blank array to append the scores at each batch/iteration for that run\n",
    "    \n",
    "    pymooproblem = Problem(n_var=problem.n_var, n_obj=problem.n_obj, n_constr=problem.n_constr, \n",
    "                  xl=np.zeros(problem.n_var), xu=np.ones(problem.n_var))\n",
    "\n",
    "    ##########\n",
    "    # generate initial training data for that run\n",
    "    train_x = initial_x\n",
    "    train_obj, train_con = problem.evaluate(train_x)\n",
    "\n",
    "    # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "    train_obj_noisy = train_obj + noise*torch.randn_like(train_obj)\n",
    "    train_con_noisy = train_con + noise*torch.randn_like(train_con)\n",
    "\n",
    "    ##########\n",
    "\n",
    "    # normalize inputs to [0,1] first before feeding into model\n",
    "    standard_bounds = torch.zeros(2, problem.n_var, **tkwargs)\n",
    "    standard_bounds[1] = 1\n",
    "    train_x_gp = normalize(train_x, problem.bounds)\n",
    "\n",
    "    # form the output train_y data by concentenating ground truth train_obj with its feasibility value on the rightmost\n",
    "    # this is necessary since the surrogate GpyTorch model needs to model BOTH obj and con for predicted candidates\n",
    "    train_y = torch.cat([train_obj_noisy, train_con_noisy], dim=-1) # model takes noisy observations\n",
    "\n",
    "    # define and train surrogate models for objective and constraint\n",
    "    models = []\n",
    "    for i in range(train_y.shape[-1]):\n",
    "        models.append(SingleTaskGP(train_x_gp, train_y[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "    model = ModelListGP(*models)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "    \n",
    "    ##########    \n",
    "    \n",
    "    def create_idxr(i):\n",
    "        def idxr(Z):\n",
    "            return Z[..., i]\n",
    "\n",
    "        return idxr\n",
    "\n",
    "    def create_idxrs():\n",
    "        return [create_idxr(i=i) for i in range(problem.n_obj, problem.n_obj+problem.n_constr)]\n",
    "    \n",
    "    ########## ########## ########## start of iteration loop\n",
    "\n",
    "    for iteration in range(1, N_BATCH + 1):   \n",
    "\n",
    "        t3 = time.time()\n",
    "\n",
    "        ##########\n",
    "\n",
    "        fit_gpytorch_model(mll)  \n",
    "\n",
    "        # define the acqusition function for EIC if feas_weighting is false\n",
    "        acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "            model=model,\n",
    "            ref_point=ref_point, # for computing HV, must flip for BoTorch\n",
    "            X_baseline=train_x_gp, # feed total list of train_x for this current iteration\n",
    "            sampler=SobolQMCNormalSampler(num_samples=128),  # determines how candidates are randomly proposed before selection\n",
    "            objective=IdentityMCMultiOutputObjective(outcomes=np.arange(problem.n_obj).tolist()), # optimize first n_obj col \n",
    "            constraints=create_idxrs(), # constraint on last n_constr col\n",
    "            prune_baseline=True, cache_pending=True)  # options for improving qNEHVI, keep these on\n",
    "\n",
    "        # propose best candidates given QMC and qNEHVI\n",
    "        qnehvi_x, _ = optimize_acqf(acq_function=acq_func,\n",
    "                                    bounds=standard_bounds, # since train_x was normalized\n",
    "                                    q=BATCH_SIZE, # no of candidates to propose in parallel, 12 is the max for a GTX1065\n",
    "                                    num_restarts=1, # no of restarts if q candidates fail to show improvement\n",
    "                                    raw_samples=256,  # pool of samples to choose the starting points from\n",
    "                                    options={\"batch_limit\": 5, \"maxiter\": 200}, # default arguments, not too sure about this yet\n",
    "                                 )\n",
    "\n",
    "        ##########\n",
    "\n",
    "        # we pick out the best points so far to form parents\n",
    "        pareto_mask = is_non_dominated(train_obj_noisy)\n",
    "        pareto_y = -train_obj_noisy[pareto_mask]\n",
    "        pareto_x = train_x_gp[pareto_mask]\n",
    "        pareto_con = train_con_noisy[pareto_mask]\n",
    "        \n",
    "        algorithm = UNSGA3(pop_size=256,\n",
    "                           ref_dirs=get_reference_directions(\"energy\", problem.n_obj, BATCH_SIZE, seed=random_state),\n",
    "                           sampling=pareto_x.cpu().numpy(),\n",
    "                          )\n",
    "\n",
    "        algorithm.setup(pymooproblem, termination=NoTermination())\n",
    "\n",
    "        # set the 1st population to the current evaluated population\n",
    "        pop = algorithm.ask()\n",
    "        pop.set(\"F\", pareto_y.cpu().numpy())\n",
    "        pop.set(\"G\", pareto_con.cpu().numpy())\n",
    "        algorithm.tell(infills=pop)\n",
    "\n",
    "        # propose children based on tournament selection -> crossover/mutation\n",
    "        newpop = algorithm.ask()\n",
    "        nsga3_x = torch.tensor(newpop.get(\"X\"), **tkwargs)\n",
    "        \n",
    "        ##########\n",
    "\n",
    "        candidates = torch.cat([qnehvi_x, nsga3_x])\n",
    "\n",
    "        acq_value_list = []\n",
    "\n",
    "        for i in range(0, candidates.shape[0]):\n",
    "            with torch.no_grad():\n",
    "                acq_value = acq_func(candidates[i].unsqueeze(dim=0))\n",
    "                acq_value_list.append(acq_value.item())\n",
    "\n",
    "        sorted_x = candidates.cpu().numpy()[np.argsort(acq_value_list)]\n",
    "\n",
    "        ##########\n",
    "        \n",
    "        new_x = torch.tensor(sorted_x[-BATCH_SIZE:], **tkwargs) # take best BATCH_SIZE samples\n",
    "        new_x =  unnormalize(new_x.detach(), bounds=problem.bounds)\n",
    "        \n",
    "        # repair new_x\n",
    "        for i in range(new_x.shape[0]):\n",
    "            if 0.3 - new_x[i,1]/new_x[i,4] > 0:\n",
    "                new_x[i,4] = min(new_x[i,1]/0.3, new_x[i,4])\n",
    "\n",
    "        for i in range(new_x.shape[0]):\n",
    "            if 2 - (new_x[i,1]/new_x[i,4]) - (new_x[i,3]/new_x[i,1]) > 0:\n",
    "                new_x[i,3] = max((2-new_x[i,1]/new_x[i,4])*new_x[i,1], new_x[i,3])\n",
    "                \n",
    "        new_obj, new_con = problem.evaluate(new_x)\n",
    "\n",
    "        # add noise, by default noise=0, so train_noisy = train, noise factor determines amt of std dev to add\n",
    "        new_obj_noisy = new_obj + noise*torch.randn_like(new_obj)\n",
    "        new_con_noisy = new_con + noise*torch.randn_like(new_con)\n",
    "\n",
    "        # update training points by concatenating the new values into their respective tensors\n",
    "        train_x = torch.cat([train_x, new_x])\n",
    "        train_obj = torch.cat([train_obj, new_obj])\n",
    "        train_con = torch.cat([train_con, new_con])\n",
    "        train_obj_noisy = torch.cat([train_obj_noisy, new_obj_noisy])\n",
    "        train_con_noisy = torch.cat([train_con_noisy, new_con_noisy])\n",
    "\n",
    "        # computing HV of current candidate list\n",
    "        is_feas = (train_con <= 0).all(dim=-1) # check whether points fit ALL (.all) constraint criteria\n",
    "        feas_train_obj = train_obj[is_feas] # take only points that fit the 1st check\n",
    "        if feas_train_obj.shape[0] > 0:\n",
    "            pareto_mask = is_non_dominated(feas_train_obj) # check for 2nd criteria: non-dominated, meaning new pareto optimal\n",
    "            pareto_y = feas_train_obj[pareto_mask] # take only points that fit the 2nd check\n",
    "            volume = hv.compute(pareto_y) # compute change in HV with new pareto optimal wrt to original ref point\n",
    "        else:\n",
    "            volume = 0.0\n",
    "\n",
    "        hvs.append(volume)\n",
    "\n",
    "        ##########\n",
    "\n",
    "        # update the surrogate models for next iteration\n",
    "        train_x_gp = normalize(train_x, problem.bounds) # dont forget to renormalize!\n",
    "        train_y = torch.cat([train_obj_noisy, train_con_noisy], dim=-1) # model takes noisy observations\n",
    "\n",
    "        models = []\n",
    "        for i in range(train_y.shape[-1]):\n",
    "            models.append(SingleTaskGP(train_x_gp, train_y[..., i : i + 1], outcome_transform=Standardize(m=1)))\n",
    "        model = ModelListGP(*models)\n",
    "        mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "        ##########\n",
    "\n",
    "        t4 = time.time()\n",
    "        if verbose:\n",
    "            print(\n",
    "                    f\"Batch {iteration:>2} of {N_BATCH}: Hypervolume = \"\n",
    "                    f\"{hvs[-1]:>4.2f}, \"\n",
    "                    f\"time = {t4-t3:>4.2f}s.\\n\"\n",
    "                    , end=\"\")\n",
    "\n",
    "        del new_x, new_obj, new_con, qnehvi_x, nsga3_x, new_obj_noisy, new_con_noisy, train_y\n",
    "        torch.cuda.empty_cache() # clear some memory here between each run/trial    \n",
    "        \n",
    "    t1 = time.time()\n",
    "    print(f\"Time taken in total: {t1-t0:>4.2f}s.\")   \n",
    "    \n",
    "    del models, model, mll\n",
    "    torch.cuda.empty_cache() # clear some memory here between each run/trial  \n",
    "    \n",
    "    # returns the HV score across iterations, total training set as an array\n",
    "    return hvs, torch.hstack([train_x, train_obj, train_con]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c630f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cond</th>\n",
       "      <th>Qtsc</th>\n",
       "      <th>Qag</th>\n",
       "      <th>Qpva</th>\n",
       "      <th>Qseed</th>\n",
       "      <th>Qaa</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20.723363</td>\n",
       "      <td>12.953919</td>\n",
       "      <td>22.057069</td>\n",
       "      <td>18.571091</td>\n",
       "      <td>9.179962</td>\n",
       "      <td>0.601600</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>0.226205</td>\n",
       "      <td>-1.111108</td>\n",
       "      <td>-8.447354e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11.441927</td>\n",
       "      <td>9.235287</td>\n",
       "      <td>7.446133</td>\n",
       "      <td>21.407840</td>\n",
       "      <td>18.947371</td>\n",
       "      <td>0.434961</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>0.108007</td>\n",
       "      <td>-0.187418</td>\n",
       "      <td>-8.054659e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.754681</td>\n",
       "      <td>11.048728</td>\n",
       "      <td>18.566012</td>\n",
       "      <td>3.432239</td>\n",
       "      <td>3.910927</td>\n",
       "      <td>0.367403</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.856990</td>\n",
       "      <td>-2.525092</td>\n",
       "      <td>-1.135738e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.449833</td>\n",
       "      <td>4.047471</td>\n",
       "      <td>12.575087</td>\n",
       "      <td>23.347719</td>\n",
       "      <td>10.787064</td>\n",
       "      <td>0.633723</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>0.027178</td>\n",
       "      <td>-0.075215</td>\n",
       "      <td>-4.143686e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.768571</td>\n",
       "      <td>7.631449</td>\n",
       "      <td>10.762707</td>\n",
       "      <td>11.340272</td>\n",
       "      <td>14.846944</td>\n",
       "      <td>0.342266</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>0.527489</td>\n",
       "      <td>-0.214008</td>\n",
       "      <td>-9.167080e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>1.468149</td>\n",
       "      <td>23.946571</td>\n",
       "      <td>20.069563</td>\n",
       "      <td>23.996267</td>\n",
       "      <td>23.996370</td>\n",
       "      <td>0.309824</td>\n",
       "      <td>0.050596</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.697925</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>1.312893</td>\n",
       "      <td>23.728265</td>\n",
       "      <td>0.676884</td>\n",
       "      <td>15.774632</td>\n",
       "      <td>17.771365</td>\n",
       "      <td>0.315712</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>0.342724</td>\n",
       "      <td>-1.035197</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>19.510866</td>\n",
       "      <td>16.252405</td>\n",
       "      <td>23.160320</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.312812</td>\n",
       "      <td>0.038633</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>-0.512953</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>23.882699</td>\n",
       "      <td>0.744571</td>\n",
       "      <td>14.982281</td>\n",
       "      <td>17.398691</td>\n",
       "      <td>0.333352</td>\n",
       "      <td>0.032074</td>\n",
       "      <td>0.375738</td>\n",
       "      <td>-1.072672</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>0.843380</td>\n",
       "      <td>23.995188</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>21.024698</td>\n",
       "      <td>21.351922</td>\n",
       "      <td>0.244499</td>\n",
       "      <td>0.035795</td>\n",
       "      <td>0.123971</td>\n",
       "      <td>-0.823795</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cond       Qtsc        Qag       Qpva      Qseed        Qaa        y1  \\\n",
       "0      1  20.723363  12.953919  22.057069  18.571091   9.179962  0.601600   \n",
       "1      2  11.441927   9.235287   7.446133  21.407840  18.947371  0.434961   \n",
       "2      3   2.754681  11.048728  18.566012   3.432239   3.910927  0.367403   \n",
       "3      4   1.449833   4.047471  12.575087  23.347719  10.787064  0.633723   \n",
       "4      5   7.768571   7.631449  10.762707  11.340272  14.846944  0.342266   \n",
       "..   ...        ...        ...        ...        ...        ...       ...   \n",
       "67    68   1.468149  23.946571  20.069563  23.996267  23.996370  0.309824   \n",
       "68    69   1.312893  23.728265   0.676884  15.774632  17.771365  0.315712   \n",
       "69    70   0.600000  19.510866  16.252405  23.160320  24.000000  0.312812   \n",
       "70    71   0.600000  23.882699   0.744571  14.982281  17.398691  0.333352   \n",
       "71    72   0.843380  23.995188   0.702247  21.024698  21.351922  0.244499   \n",
       "\n",
       "          y2        y3        c1            c2  \n",
       "0   0.013235  0.226205 -1.111108 -8.447354e-01  \n",
       "1   0.017346  0.108007 -0.187418 -8.054659e-01  \n",
       "2   0.005619  0.856990 -2.525092 -1.135738e+00  \n",
       "3   0.011473  0.027178 -0.075215 -4.143686e+00  \n",
       "4   0.012207  0.527489 -0.214008 -9.167080e-10  \n",
       "..       ...       ...       ...           ...  \n",
       "67  0.050596  0.000156 -0.697925  0.000000e+00  \n",
       "68  0.033536  0.342724 -1.035197  0.000000e+00  \n",
       "69  0.038633  0.034987 -0.512953 -2.220446e-16  \n",
       "70  0.032074  0.375738 -1.072672  0.000000e+00  \n",
       "71  0.035795  0.123971 -0.823795  0.000000e+00  \n",
       "\n",
       "[72 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Results_Run15.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1d25730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_torch = torch.tensor(df[df.columns[1:]].values, **tkwargs) # excluding condition no\n",
    "train_x = df_torch[...,0:5]\n",
    "train_y = df_torch[...,5:7]\n",
    "\n",
    "true_bounds = torch.tensor([[0.6,  0.6,  0.6,  0.6,  0.6], \n",
    "                       [24,  24,  24,  24,  24]], **tkwargs)\n",
    "train_x = normalize(train_x, true_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_bounds = torch.zeros(2, problem.n_var, **tkwargs)\n",
    "standard_bounds[1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9537cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.723, 12.954, 22.057, 18.571,  9.180],\n",
       "        [11.442,  9.235,  7.446, 21.408, 18.947],\n",
       "        [ 2.755, 11.049, 18.566,  3.432,  3.911],\n",
       "        [ 1.450,  4.047, 12.575, 23.348, 10.787],\n",
       "        [ 7.769,  7.631, 10.763, 11.340, 14.847],\n",
       "        [16.995, 19.446,  1.909,  1.418,  4.700],\n",
       "        [ 5.439, 22.900, 16.768, 11.885, 12.931],\n",
       "        [13.626,  4.501,  9.907,  5.439,  1.675],\n",
       "        [ 9.258, 17.783,  5.512, 15.917,  7.128],\n",
       "        [23.729, 14.791,  3.536, 19.265, 21.206],\n",
       "        [15.888, 20.662, 20.214, 22.340, 22.488],\n",
       "        [19.595,  1.448, 15.552, 13.338,  4.827],\n",
       "        [ 8.211, 20.598, 10.777,  2.614,  4.757],\n",
       "        [18.630, 22.923,  1.909,  5.548, 13.039],\n",
       "        [16.995, 22.832,  1.710,  4.568, 12.685],\n",
       "        [20.229, 23.470, 18.064,  2.665, 11.710],\n",
       "        [ 8.211, 20.598, 10.777, 12.335, 14.700],\n",
       "        [ 6.848, 22.871,  9.856,  0.600,  0.600],\n",
       "        [ 3.770, 23.938,  8.262, 20.266, 20.755],\n",
       "        [19.132, 23.922, 22.201, 23.988, 23.988],\n",
       "        [ 5.312, 23.020, 10.777,  2.749,  4.757],\n",
       "        [ 0.600, 24.000, 24.000,  0.600,  6.017],\n",
       "        [ 0.600, 23.049,  0.600, 15.564, 17.399],\n",
       "        [ 7.464, 24.000, 10.725,  0.600,  5.662],\n",
       "        [ 8.211, 20.561, 10.777, 12.128,  4.885],\n",
       "        [ 0.821, 22.901,  0.645, 11.885, 12.670],\n",
       "        [11.690, 20.481,  7.617, 23.484, 24.000],\n",
       "        [ 9.116, 22.749,  9.785,  7.317,  5.235],\n",
       "        [23.729, 23.959,  2.051, 16.418, 18.224],\n",
       "        [ 0.600, 24.000,  6.619, 24.000, 24.000],\n",
       "        [ 0.600, 23.947, 22.743, 23.996, 23.996],\n",
       "        [ 0.600, 24.000,  0.600, 23.959, 23.960],\n",
       "        [ 7.677, 19.446,  1.909,  1.419,  4.700],\n",
       "        [ 7.464, 23.995,  0.702,  1.913,  5.940],\n",
       "        [10.774, 24.000, 21.163, 24.000, 24.000],\n",
       "        [ 0.600, 20.166,  8.979, 23.388, 24.000],\n",
       "        [ 0.600, 23.947, 22.299, 23.974, 23.974],\n",
       "        [ 0.760, 23.947, 10.886, 23.999, 23.999],\n",
       "        [ 0.600, 24.000, 10.981, 23.906, 23.907],\n",
       "        [ 0.644, 24.000,  6.244, 24.000, 24.000],\n",
       "        [ 7.677, 19.446, 20.202, 22.487, 23.051],\n",
       "        [ 7.368, 23.915, 12.371, 23.856, 23.856],\n",
       "        [ 0.600, 23.882, 12.737, 15.564, 17.399],\n",
       "        [ 1.118, 24.000,  1.538, 24.000, 24.000],\n",
       "        [23.729, 19.446,  1.924, 21.060, 21.206],\n",
       "        [12.777, 18.908, 22.137, 22.873, 23.925],\n",
       "        [ 3.770, 23.993,  8.292, 20.250, 20.755],\n",
       "        [ 0.600,  0.600,  0.600,  0.600,  0.600],\n",
       "        [ 0.600, 24.000, 24.000, 24.000, 24.000],\n",
       "        [ 0.600, 19.904,  2.234, 23.283, 23.974],\n",
       "        [ 0.600, 23.980,  5.314, 23.995, 23.995],\n",
       "        [ 0.642, 23.882,  1.856, 16.776, 18.406],\n",
       "        [ 0.600, 23.999,  4.777, 24.000, 24.000],\n",
       "        [ 0.600, 23.989, 24.000, 21.296, 21.568],\n",
       "        [ 0.600, 19.904,  2.234, 23.283, 23.974],\n",
       "        [ 0.600, 24.000, 13.973, 23.998, 23.998],\n",
       "        [13.362, 19.067, 11.730, 22.982, 23.994],\n",
       "        [ 7.726, 23.947,  1.093, 23.974, 23.974],\n",
       "        [13.956, 22.568,  0.600, 23.915, 24.000],\n",
       "        [ 0.600, 24.000, 13.083, 24.000, 24.000],\n",
       "        [ 7.726, 23.947,  1.093, 23.974, 23.974],\n",
       "        [ 0.600, 23.989,  0.928,  7.725, 14.297],\n",
       "        [ 0.631, 23.728,  0.677, 15.386, 17.556],\n",
       "        [ 0.600, 24.000, 15.204, 23.995, 23.995],\n",
       "        [ 0.980, 23.995,  0.702, 21.025, 21.352],\n",
       "        [ 0.600, 20.454, 16.599, 23.476, 24.000],\n",
       "        [ 0.600, 23.992, 22.601, 23.993, 23.993],\n",
       "        [ 1.468, 23.947, 20.070, 23.996, 23.996],\n",
       "        [ 1.313, 23.728,  0.677, 15.775, 17.771],\n",
       "        [ 0.600, 19.511, 16.252, 23.160, 24.000],\n",
       "        [ 0.600, 23.883,  0.745, 14.982, 17.399],\n",
       "        [ 0.843, 23.995,  0.702, 21.025, 21.352]], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnormalize(train_x, true_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3caad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac42a30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50/500 - Loss: 1.554 noise: 1.571\n",
      "Epoch 100/500 - Loss: 1.444 noise: 1.064\n",
      "Epoch 150/500 - Loss: 1.344 noise: 0.693\n",
      "Epoch 200/500 - Loss: 1.253 noise: 0.454\n",
      "Epoch 250/500 - Loss: 1.148 noise: 0.287\n",
      "Epoch 300/500 - Loss: 1.042 noise: 0.171\n",
      "Epoch 350/500 - Loss: 0.964 noise: 0.105\n",
      "Epoch 400/500 - Loss: 0.924 noise: 0.072\n",
      "Epoch 450/500 - Loss: 0.908 noise: 0.058\n",
      "Epoch 500/500 - Loss: 0.902 noise: 0.051\n"
     ]
    }
   ],
   "source": [
    "model1 = SingleTaskGP(train_X=train_x, train_Y=train_y[...,0].unsqueeze(1), outcome_transform=Standardize(m=1))\n",
    "model1.likelihood.noise_covar.register_constraint(\"raw_noise\", GreaterThan(1e-5))\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(likelihood=model1.likelihood, model=model1)\n",
    "# set mll and all submodules to the specified dtype and device\n",
    "mll = mll.to(train_x)\n",
    "\n",
    "optimizer = SGD([{'params': model1.parameters()}], lr=0.1)\n",
    "\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "model1.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass through the model to obtain the output MultivariateNormal\n",
    "    output = model1(train_x)\n",
    "    # Compute negative marginal log likelihood\n",
    "    loss = - mll(output, model1.train_targets)\n",
    "    # back prop gradients\n",
    "    loss.backward()\n",
    "    # print every 10 iterations\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:>3}/{NUM_EPOCHS} - Loss: {loss.item():>4.3f} \"\n",
    "            #f\"lengthscale: {model.covar_module.base_kernel.lengthscale} \" \n",
    "            f\"noise: {model1.likelihood.noise.item():>4.3f}\" \n",
    "         )\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9472ee3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50/500 - Loss: 1.359 noise: 1.338\n",
      "Epoch 100/500 - Loss: 1.039 noise: 0.591\n",
      "Epoch 150/500 - Loss: 0.668 noise: 0.191\n",
      "Epoch 200/500 - Loss: 0.457 noise: 0.077\n",
      "Epoch 250/500 - Loss: 0.401 noise: 0.050\n",
      "Epoch 300/500 - Loss: 0.390 noise: 0.044\n",
      "Epoch 350/500 - Loss: 0.387 noise: 0.043\n",
      "Epoch 400/500 - Loss: 0.385 noise: 0.042\n",
      "Epoch 450/500 - Loss: 0.385 noise: 0.042\n",
      "Epoch 500/500 - Loss: 0.384 noise: 0.042\n"
     ]
    }
   ],
   "source": [
    "model2 = SingleTaskGP(train_X=train_x, train_Y=train_y[...,1].unsqueeze(1), outcome_transform=Standardize(m=1))\n",
    "model2.likelihood.noise_covar.register_constraint(\"raw_noise\", GreaterThan(1e-5))\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(likelihood=model2.likelihood, model=model2)\n",
    "# set mll and all submodules to the specified dtype and device\n",
    "mll = mll.to(train_x)\n",
    "\n",
    "optimizer = SGD([{'params': model2.parameters()}], lr=0.1)\n",
    "\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "model2.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass through the model to obtain the output MultivariateNormal\n",
    "    output = model2(train_x)\n",
    "    # Compute negative marginal log likelihood\n",
    "    loss = - mll(output, model2.train_targets)\n",
    "    # back prop gradients\n",
    "    loss.backward()\n",
    "    # print every 10 iterations\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:>3}/{NUM_EPOCHS} - Loss: {loss.item():>4.3f} \"\n",
    "            #f\"lengthscale: {model.covar_module.base_kernel.lengthscale} \" \n",
    "            f\"noise: {model2.likelihood.noise.item():>4.3f}\" \n",
    "         )\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d1202c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols = 2, figsize = (12,8))\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "for i, model, obj in zip([0,1],\n",
    "                        [model1, model2],\n",
    "                        [\"Obj1 (Cosine Similarity)\", \"Obj2 (Reaction Rate)\"]):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_true = train_y[...,i]\n",
    "        posterior = model.posterior(train_x)  \n",
    "        y_pred = posterior.mean.squeeze()\n",
    "        lower, upper = posterior.mvn.confidence_region()\n",
    "        yerr = upper-lower\n",
    "\n",
    "        ax[i].axline((1, 1), slope=1)\n",
    "\n",
    "        ax[i].errorbar(x=y_true.cpu().numpy(), y=y_pred.cpu().numpy(), yerr=yerr.cpu().numpy(), ls='', \n",
    "                        marker='D', mec='w', mew=0.2, mfc='r', c='r', \n",
    "                        #label='{:} R$^2$={:.3f}'.format(s,r2)\n",
    "                       )\n",
    "\n",
    "        ax[i].set_title(obj)\n",
    "        ax[i].set_xlabel('True Value')\n",
    "    \n",
    "ax[0].set_ylabel('Predicted Value')\n",
    "fig.suptitle('sklearn GP Regressor')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fbe8d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem_AgNP(torch.nn.Module):\n",
    "    \n",
    "    name = 'AgNp'\n",
    "    \n",
    "    #must define these!\n",
    "    n_var = 5\n",
    "    n_obj = 3\n",
    "    n_constr = 2\n",
    "    \n",
    "    ref_point = torch.tensor([0,0,0], **tkwargs)\n",
    "        \n",
    "    # input bounds, don't forget to change according to n_var!  \n",
    "    bounds = torch.tensor([[0,  0,  0,  0,  0], [1,  1,  1,  1,  1]], **tkwargs)\n",
    "\n",
    "    def evaluate(X):\n",
    "    \n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "\n",
    "            y1 = model1.posterior(X).mean.squeeze(1)\n",
    "            y2 = model2.posterior(X).mean.squeeze(1)\n",
    "            y3 = 1-X[...,3]\n",
    "\n",
    "            output = torch.stack([y1,y2,y3], dim=1).squeeze(1)\n",
    "\n",
    "            X = unnormalize(X, bounds=true_bounds)\n",
    "            c1 = 0.3 - X[...,1]/X[...,4]\n",
    "            c2 = 2 - (X[...,1]/X[...,4]) - (X[...,3]/X[...,1])\n",
    "\n",
    "            slack = torch.stack([c1,c2], dim=1).squeeze(1)\n",
    "        \n",
    "        return output, slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb1ba457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial  1 of 3 for problem AgNp with d = 5\n",
      "Optimizing with Pure qNEHVI\n",
      "Batch  1 of 15: Hypervolume = 0.00, time = 3.36s.\n",
      "Batch  2 of 15: Hypervolume = 0.00, time = 11.05s.\n",
      "Batch  3 of 15: Hypervolume = 0.00, time = 15.02s.\n",
      "Batch  4 of 15: Hypervolume = 0.00, time = 35.76s.\n",
      "Batch  5 of 15: Hypervolume = 0.00, time = 14.48s.\n",
      "Batch  6 of 15: Hypervolume = 0.00, time = 25.06s.\n",
      "Batch  7 of 15: Hypervolume = 0.00, time = 8.98s.\n",
      "Batch  8 of 15: Hypervolume = 0.01, time = 37.59s.\n",
      "Batch  9 of 15: Hypervolume = 0.01, time = 36.05s.\n",
      "Batch 10 of 15: Hypervolume = 0.01, time = 44.67s.\n",
      "Batch 11 of 15: Hypervolume = 0.01, time = 18.33s.\n",
      "Batch 12 of 15: Hypervolume = 0.01, time = 34.44s.\n",
      "Batch 13 of 15: Hypervolume = 0.01, time = 49.29s.\n",
      "Batch 14 of 15: Hypervolume = 0.01, time = 32.81s.\n",
      "Batch 15 of 15: Hypervolume = 0.01, time = 41.65s.\n",
      "Time taken in total: 408.57s.\n",
      "Optimizing with Hybrid qNEHVI + U-NSGA-III\n",
      "Batch  1 of 15: Hypervolume = 0.00, time = 7.30s.\n",
      "Batch  2 of 15: Hypervolume = 0.00, time = 10.42s.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Population Set Attribute Error: Number of values and population size do not match!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m         initial_x[i,\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m-\u001b[39minitial_x[i,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39minitial_x[i,\u001b[38;5;241m4\u001b[39m])\u001b[38;5;241m*\u001b[39minitial_x[i,\u001b[38;5;241m1\u001b[39m], initial_x[i,\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m algo, hv_list, train_list \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m     34\u001b[0m     [optimize_qnehvi, optimize_hybrid_nsga],\n\u001b[0;32m     35\u001b[0m     [hvs_qnehvi1, hvs_hybrid1],\n\u001b[0;32m     36\u001b[0m     [train_qnehvi1, train_hybrid1],\n\u001b[0;32m     37\u001b[0m ):\n\u001b[1;32m---> 40\u001b[0m     hv, train \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_point1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mN_BATCH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_BATCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     hv_list\u001b[38;5;241m.\u001b[39mappend(hv)\n\u001b[0;32m     44\u001b[0m     train_list\u001b[38;5;241m.\u001b[39mappend(train)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36moptimize_hybrid_nsga\u001b[1;34m(problem, ref_point, initial_x, N_BATCH, BATCH_SIZE, random_state, noise, verbose)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# set the 1st population to the current evaluated population\u001b[39;00m\n\u001b[0;32m     99\u001b[0m pop \u001b[38;5;241m=\u001b[39m algorithm\u001b[38;5;241m.\u001b[39mask()\n\u001b[1;32m--> 100\u001b[0m \u001b[43mpop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpareto_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m pop\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m\"\u001b[39m, pareto_con\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m    102\u001b[0m algorithm\u001b[38;5;241m.\u001b[39mtell(infills\u001b[38;5;241m=\u001b[39mpop)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pymoo\\core\\population.py:41\u001b[0m, in \u001b[0;36mPopulation.set\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m is_iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(values, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__len__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPopulation Set Attribute Error: Number of values and population size do not match!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[0;32m     44\u001b[0m     val \u001b[38;5;241m=\u001b[39m values[i] \u001b[38;5;28;01mif\u001b[39;00m is_iterable \u001b[38;5;28;01melse\u001b[39;00m values\n",
      "\u001b[1;31mException\u001b[0m: Population Set Attribute Error: Number of values and population size do not match!"
     ]
    }
   ],
   "source": [
    "problem = Problem_AgNP\n",
    "\n",
    "N_TRIALS = 3\n",
    "verbose = True\n",
    "noise = 0.00\n",
    "\n",
    "N_BATCH = 15\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "ref_point1 = torch.tensor([0,0,0], **tkwargs)\n",
    "ref_point2 = torch.tensor([0,0,0.5], **tkwargs)\n",
    "\n",
    "hvs_qnehvi1, hvs_qnehvi2, hvs_hybrid1, hvs_hybrid2 = [], [], [], []\n",
    "train_qnehvi1, train_qnehvi2, train_hybrid1, train_hybrid2 = [], [], [], []\n",
    "\n",
    "# main loop for each trial/run, random_state will be trial number\n",
    "for trial in range(1, N_TRIALS + 1):\n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} for problem {problem.name} with d = {problem.n_var}\\n\", end=\"\")\n",
    "\n",
    "    # initialize with a 2*(d+1) sample set\n",
    "\n",
    "    initial_x = draw_sobol_samples(bounds=problem.bounds,n=1, q=12, seed=trial).squeeze(0)\n",
    "    \n",
    "    # repair inputs to feasibility\n",
    "    for i in range(initial_x.shape[0]):\n",
    "        if 0.3 - initial_x[i,1]/initial_x[i,4] > 0:\n",
    "            initial_x[i,4] = min(initial_x[i,1]/0.3, initial_x[i,4])\n",
    "\n",
    "    for i in range(initial_x.shape[0]):\n",
    "        if 2 - (initial_x[i,1]/initial_x[i,4]) - (initial_x[i,3]/initial_x[i,1]) > 0:\n",
    "            initial_x[i,3] = max((2-initial_x[i,1]/initial_x[i,4])*initial_x[i,1], initial_x[i,3])\n",
    "                \n",
    "    for algo, hv_list, train_list in zip(\n",
    "        [optimize_qnehvi, optimize_hybrid_nsga],\n",
    "        [hvs_qnehvi1, hvs_hybrid1],\n",
    "        [train_qnehvi1, train_hybrid1],\n",
    "    ):\n",
    "    \n",
    "    \n",
    "        hv, train = algo(problem, ref_point1, initial_x,\n",
    "                         N_BATCH=N_BATCH, BATCH_SIZE=BATCH_SIZE,\n",
    "                         random_state=trial, noise=noise, verbose=verbose)\n",
    "        hv_list.append(hv)\n",
    "        train_list.append(train)\n",
    "    \n",
    "for algo_name, hv_list, train_list in zip(['qnehvi', 'hybrid',],\n",
    "                                          [hvs_qnehvi1, hvs_hybrid1],\n",
    "                                          [train_qnehvi1, train_hybrid1]\n",
    "                                         ):\n",
    "    \n",
    "    savetxt(f\"{problem.name}_hvs_{algo_name}_{N_BATCH}by{BATCH_SIZE}_{N_TRIALS}trials.csv\", hv_list, delimiter=',')    \n",
    "    savetxt(f\"{problem.name}_train_{algo_name}_{N_BATCH}by{BATCH_SIZE}_{N_TRIALS}trials.csv\", np.array(train_list).reshape(-1), delimiter=',')\n",
    "\n",
    "print(\"ALL DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa47dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c09c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8c9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4fd3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = Problem_AgNP\n",
    "\n",
    "N_BATCH = 15\n",
    "BATCH_SIZE = 4\n",
    "N_TRIALS = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "\n",
    "for algo_name, plot_name, in zip(\n",
    "    ['qnehvi', 'hybrid'],\n",
    "    ['Pure BO',  'Hybrid w/ NSGA']):\n",
    "    \n",
    "    hv_list = loadtxt(f\"{problem.name}_hvs_{algo_name}_{N_BATCH}by{BATCH_SIZE}_{N_TRIALS}trials.csv\", delimiter=',')    \n",
    "    hv_plot = np.asarray(hv_list)\n",
    "\n",
    "    '''    \n",
    "    ax.plot(np.arange(N_BATCH),\n",
    "            hv_plot.mean(axis=0),\n",
    "            label=f'{plot_name}', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "    ax.fill_between(np.arange(N_BATCH),\n",
    "                    hv_plot.mean(axis=0)-ci(hv_plot, N_TRIALS), hv_plot.mean(axis=0)+ci(hv_plot, N_TRIALS),\n",
    "                    alpha=0.3)\n",
    "    '''\n",
    "    \n",
    "    ax.plot(np.arange(N_BATCH),\n",
    "            hv_plot,\n",
    "            label=f'{plot_name}', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "ax.set(xlabel='Iterations')\n",
    "ax.grid(True)\n",
    "ax.set_title(f\"{problem.name} (d={problem.n_var}), {N_BATCH} x {BATCH_SIZE}\", fontsize=18)\n",
    "ax.set(ylabel='Hypervolume')\n",
    "ax.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02999c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = Problem_AgNP\n",
    "\n",
    "N_BATCH = 15\n",
    "BATCH_SIZE = 4\n",
    "N_TRIALS = 1\n",
    "   \n",
    "newdict = {}\n",
    "a = 2*(problem.n_var+1)\n",
    "b = 2*(problem.n_var+1)+BATCH_SIZE-1\n",
    "for i in range(0, N_BATCH):\n",
    "\n",
    "    newdict[i] = (a, b)\n",
    "    a+=BATCH_SIZE\n",
    "    b+=BATCH_SIZE  \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "\n",
    "for algo_name, plot_name, in zip(\n",
    "    ['qnehvi', 'hybrid'],\n",
    "    ['Pure BO', 'Hybrid w/ NSGA'],):\n",
    "    \n",
    "    train = loadtxt(f\"{problem.name}_train_{algo_name}_{N_BATCH}by{BATCH_SIZE}_{N_TRIALS}trials.csv\", delimiter=',')    \n",
    "    train = train.reshape(N_TRIALS, N_BATCH*BATCH_SIZE + 2*(problem.n_var+1), problem.n_var+problem.n_obj+problem.n_constr)\n",
    "\n",
    "    '''\n",
    "    feas_list = []\n",
    "    for trial in range(N_TRIALS):\n",
    "        train_con = torch.tensor(train[trial][:,-problem.n_constr:], **tkwargs)\n",
    "        for row in range(0, train_con.shape[0]):\n",
    "            for col in range(0, train_con.shape[1]):\n",
    "                if train_con[row,col]<=0:\n",
    "                    train_con[row,col]=0\n",
    "\n",
    "        feas_combined = train_con.sum(dim=1)\n",
    "        feas_value = torch.log(feas_combined.max()) -torch.log(feas_combined+feas_combined.max())\n",
    "\n",
    "        feas_list_inner = []\n",
    "        for i in range(N_BATCH):\n",
    "            feas_list_inner.append(feas_value[newdict[i][0]:newdict[i][1]].sum().cpu().numpy())\n",
    "\n",
    "        feas_list.append(feas_list_inner)\n",
    "        '''\n",
    "        \n",
    "    feas_list = []\n",
    "    train_con = torch.tensor(train[:,-problem.n_constr:], **tkwargs)\n",
    "    for row in range(0, train_con.shape[0]):\n",
    "        for col in range(0, train_con.shape[1]):\n",
    "            if train_con[row,col]<=0:\n",
    "                train_con[row,col]=0\n",
    "\n",
    "    feas_combined = train_con.sum(dim=1)\n",
    "    feas_value = torch.log(feas_combined.max()) -torch.log(feas_combined+feas_combined.max())\n",
    "\n",
    "    feas_list_inner = []\n",
    "    for i in range(N_BATCH):\n",
    "        feas_list_inner.append(feas_value[newdict[i][0]:newdict[i][1]].sum().cpu().numpy())\n",
    "\n",
    "    feas_list.append(feas_list_inner)\n",
    "\n",
    "\n",
    "    feas_plot = np.array(feas_list)    \n",
    "        \n",
    "    ax.plot(np.arange(N_BATCH),\n",
    "            feas_plot[:,1],\n",
    "            label=f'{plot_name}', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "    '''    \n",
    "    ax.fill_between(np.arange(N_BATCH),\n",
    "                    feas_plot.mean(axis=0)-ci(feas_plot, N_TRIALS), feas_plot.mean(axis=0)+ci(feas_plot, N_TRIALS),\n",
    "                    alpha=0.3)\n",
    "    '''\n",
    " \n",
    "ax.set_ylim(None, 0.05)\n",
    "ax.set(xlabel='Iterations')\n",
    "ax.grid(True)\n",
    "ax.set_title(f\"{problem.name} (d={problem.n_var})\", fontsize=18)\n",
    "ax.set(ylabel='Feasibility Achievement')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba2c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_name = 'Pure BO'\n",
    "algo_name = 'qnehvi'\n",
    "    \n",
    "train = loadtxt(f\"{problem.name}_train_{algo_name}_{N_BATCH}by{BATCH_SIZE}_{N_TRIALS}trials.csv\", delimiter=',')    \n",
    "train = train.reshape(N_TRIALS, N_BATCH*BATCH_SIZE + 2*(problem.n_var+1), problem.n_var+problem.n_obj+problem.n_constr)\n",
    "train = train[0][:,problem.n_var:problem.n_var+problem.n_obj]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter3D(train[:,0], train[:,1], train[:,2], s=20, #c=zz1, #norm=norm, cmap='magma'\n",
    "            )\n",
    "\n",
    "\n",
    "ax.set_title(f\"{problem.name} (d={problem.n_var})\\n{plot_name} ({N_BATCH} x {BATCH_SIZE})\", fontsize=16)\n",
    "\n",
    "ax.set_xlabel('f1', fontsize=11)\n",
    "ax.set_ylabel('f2', fontsize=11)\n",
    "ax.set_zlabel('f3', fontsize=11)\n",
    "\n",
    "plt.rc('xtick', labelsize=11)\n",
    "plt.rc('ytick', labelsize=11)\n",
    "#plt.rc('ztick', labelsize=11)\n",
    "\n",
    "#ax.view_init(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_name = 'Hybrid'\n",
    "algo_name = 'hybrid'\n",
    "    \n",
    "train = loadtxt(f\"{problem.name}_train_{algo_name}_{N_BATCH}by{BATCH_SIZE}_{N_TRIALS}trials.csv\", delimiter=',')    \n",
    "train = train.reshape(N_TRIALS, N_BATCH*BATCH_SIZE + 2*(problem.n_var+1), problem.n_var+problem.n_obj+problem.n_constr)\n",
    "train = train[0][:,problem.n_var:problem.n_var+problem.n_obj]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter3D(train[:,0], train[:,1], train[:,2], s=20, #c=zz1, #norm=norm, cmap='magma'\n",
    "            )\n",
    "\n",
    "\n",
    "ax.set_title(f\"{problem.name} (d={problem.n_var})\\n{plot_name} ({N_BATCH} x {BATCH_SIZE})\", fontsize=16)\n",
    "\n",
    "ax.set_xlabel('f1', fontsize=11)\n",
    "ax.set_ylabel('f2', fontsize=11)\n",
    "ax.set_zlabel('f3', fontsize=11)\n",
    "\n",
    "plt.rc('xtick', labelsize=11)\n",
    "plt.rc('ytick', labelsize=11)\n",
    "#plt.rc('ztick', labelsize=11)\n",
    "\n",
    "#ax.view_init(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_name = 'qnehvi'\n",
    "    \n",
    "train = loadtxt(f\"{problem.name}_train_{algo_name}_{N_BATCH}by{BATCH_SIZE}_{N_TRIALS}trials.csv\", delimiter=',')    \n",
    "train = train.reshape(N_TRIALS, N_BATCH*BATCH_SIZE + 2*(problem.n_var+1), problem.n_var+problem.n_obj+problem.n_constr)\n",
    "train1 = train[0][:,problem.n_var:problem.n_var+problem.n_obj]\n",
    "\n",
    "algo_name = 'hybrid'\n",
    "    \n",
    "train = loadtxt(f\"{problem.name}_train_{algo_name}_{N_BATCH}by{BATCH_SIZE}_{N_TRIALS}trials.csv\", delimiter=',')    \n",
    "train = train.reshape(N_TRIALS, N_BATCH*BATCH_SIZE + 2*(problem.n_var+1), problem.n_var+problem.n_obj+problem.n_constr)\n",
    "train2 = train[0][:,problem.n_var:problem.n_var+problem.n_obj]\n",
    "\n",
    "\n",
    "for angle in [40, 70, 100]:\n",
    "    fig = plt.figure(figsize=(14, 5))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "    ax.scatter3D(train1[:,0], train1[:,1], train1[:,2], s=20, c='r', label='Pure BO'\n",
    "                )\n",
    "    ax.scatter3D(train2[:,0], train2[:,1], train2[:,2], s=20, c='b', label='Hybrid'\n",
    "                )\n",
    "\n",
    "    ax.set_title(f\"{problem.name} ({N_BATCH} x {BATCH_SIZE})\", fontsize=14)\n",
    "\n",
    "    ax.set_xlabel('f1', fontsize=11)\n",
    "    ax.set_ylabel('f2', fontsize=11)\n",
    "    ax.set_zlabel('f3', fontsize=11)\n",
    "\n",
    "    plt.rc('xtick', labelsize=11)\n",
    "    plt.rc('ytick', labelsize=11)\n",
    "\n",
    "    ax.view_init(20, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2547d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize=(21, 7))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter3D(train1[:,0], train1[:,1], train1[:,2], s=40, c='r', label='Pure BO'\n",
    "            )\n",
    "ax.scatter3D(train2[:,0], train2[:,1], train2[:,2], s=40, c='b', label='Hybrid'\n",
    "            )\n",
    "\n",
    "ax.set_title(f\"{problem.name} ({N_BATCH} x {BATCH_SIZE})\", fontsize=14)\n",
    "\n",
    "ax.set_xlabel('f1', fontsize=11)\n",
    "ax.set_ylabel('f2', fontsize=11)\n",
    "ax.set_zlabel('f3', fontsize=11)\n",
    "\n",
    "plt.rc('xtick', labelsize=11)\n",
    "plt.rc('ytick', labelsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb16a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1e0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
